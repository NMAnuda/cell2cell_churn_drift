{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27279021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Root: c:\\Users\\anuda\\Desktop\\cell2cell_churn_drift\n",
      "Looking for: data/raw/cell2cellholdout.csv\n",
      "File Exists? True\n",
      "Success! Shape: (51047, 58)\n",
      "Columns: ['CustomerID', 'Churn', 'MonthlyRevenue', 'MonthlyMinutes', 'TotalRecurringCharge', 'DirectorAssistedCalls', 'OverageMinutes', 'RoamingCalls', 'PercChangeMinutes', 'PercChangeRevenues']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = r'c:\\Users\\anuda\\Desktop\\cell2cell_churn_drift'\n",
    "os.chdir(project_root)\n",
    "sys.path.insert(0, project_root)\n",
    "from src.config import RAW_DATA \n",
    "\n",
    "print(\"Project Root:\", os.getcwd()) \n",
    "print(\"Looking for:\", RAW_DATA)\n",
    "print(\"File Exists?\", os.path.exists(RAW_DATA))\n",
    "\n",
    "# Quick peek if it exists\n",
    "if os.path.exists(RAW_DATA):\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(RAW_DATA)\n",
    "    print(\"Success! Shape:\", df.shape)\n",
    "    print(\"Columns:\", df.columns.tolist()[:10]) \n",
    "else:\n",
    "    print(\"File not found — double-check download/path!\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee9a8c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shape: (51047, 58)\n",
      "Raw Churn sample: ['Yes', 'Yes', 'No', 'No', 'Yes']\n",
      "Processed Churn distribution:\n",
      "Churn\n",
      "0    0.711815\n",
      "1    0.288185\n",
      "Name: proportion, dtype: float64\n",
      "Using 8 numerics\n",
      "MonthlyRevenue dtype after fix: float64\n",
      "MonthlyMinutes dtype after fix: float64\n",
      "TotalRecurringCharge dtype after fix: float64\n",
      "DirectorAssistedCalls dtype after fix: float64\n",
      "OverageMinutes dtype after fix: float64\n",
      "RoamingCalls dtype after fix: float64\n",
      "PercChangeMinutes dtype after fix: float64\n",
      "PercChangeRevenues dtype after fix: float64\n",
      "Processed saved: data/processed/churn_processed.csv\n",
      "Processed head (Churn + first few):\n",
      "   Churn  MonthlyRevenue  MonthlyMinutes  TotalRecurringCharge\n",
      "0      1       -0.783096       -0.578622             -1.042504\n",
      "1      1       -0.940828       -0.973610             -1.252478\n",
      "2      0       -0.468083       -0.977390             -0.370584\n",
      "3      0        0.528260        1.487037              1.183229\n",
      "4      1       -0.937453       -0.992509             -1.252478\n",
      "Processed shape: (51047, 57)\n",
      " Batch 0 shape: (10209, 57) | Churn rate: 29.36%\n",
      " Batch 1 shape: (10209, 57) | Churn rate: 29.29%\n",
      " Batch 2 shape: (10209, 57) | Churn rate: 32.82%\n",
      " Batch 3 shape: (10209, 57) | Churn rate: 30.88%\n",
      " Batch 4 shape: (10211, 57) | Churn rate: 21.74%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "project_root = r'c:\\Users\\anuda\\Desktop\\cell2cell_churn_drift'\n",
    "os.chdir(project_root)\n",
    "import sys\n",
    "sys.path.insert(0, project_root)\n",
    "from src.config import TARGET\n",
    "\n",
    "from src.data.preprocessing import load_and_preprocess, generate_batches\n",
    "\n",
    "df_processed, scaler, le = load_and_preprocess()\n",
    "print(f\"Processed shape: {df_processed.shape}\")\n",
    "\n",
    "\n",
    "batches = generate_batches(df_processed, n_batches=5)\n",
    "for i, batch in enumerate(batches):\n",
    "    batch.to_csv(f\"data/batches/batch_{i}.csv\", index=False)\n",
    "    print(f\" Batch {i} shape: {batch.shape} | Churn rate: {batch[TARGET].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e8d032f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch    Churn  MonthlyRevenue  MonthlyMinutes  TotalRecurringCharge  \\\n",
      "0      0       -0.940828       -0.984950             -1.252478   \n",
      "1      0        0.275574        0.307741              0.553305   \n",
      "2      0       -0.312151        0.224585             -0.076620   \n",
      "3      0       -0.110767       -0.916914              0.763280   \n",
      "4      0        0.442306        3.214404              1.687169   \n",
      "\n",
      "   DirectorAssistedCalls  OverageMinutes  RoamingCalls  PercChangeMinutes  \\\n",
      "0              -0.401392       -0.413790     -0.125718           0.068207   \n",
      "1              -0.068867        0.125288     -0.125718          -0.220196   \n",
      "2               1.153384       -0.227186     -0.125718           0.403378   \n",
      "3              -0.401392       -0.413790     -0.125718          -0.099379   \n",
      "4               0.043472       -0.403423     -0.125718           1.556989   \n",
      "\n",
      "   PercChangeRevenues  DroppedCalls  ...  ReferralsMadeBySubscriber  \\\n",
      "0            0.030066           0.0  ...                          0   \n",
      "1           -0.309759           9.3  ...                          1   \n",
      "2            0.661532           3.7  ...                          0   \n",
      "3           -0.941224           0.3  ...                          0   \n",
      "4            0.027530          18.7  ...                          0   \n",
      "\n",
      "   IncomeGroup  OwnsMotorcycle  AdjustmentsToCreditRating  HandsetPrice  \\\n",
      "0            7              No                          0            10   \n",
      "1            5              No                          0            60   \n",
      "2            0              No                          0       Unknown   \n",
      "3            9              No                          0       Unknown   \n",
      "4            5              No                          0            30   \n",
      "\n",
      "   MadeCallToRetentionTeam  CreditRating  PrizmCode    Occupation  \\\n",
      "0                      Yes     1-Highest       Town  Professional   \n",
      "1                       No         5-Low      Other        Crafts   \n",
      "2                       No        2-High   Suburban         Other   \n",
      "3                       No        2-High       Town  Professional   \n",
      "4                       No         5-Low       Town         Other   \n",
      "\n",
      "   MaritalStatus  \n",
      "0            Yes  \n",
      "1            Yes  \n",
      "2        Unknown  \n",
      "3            Yes  \n",
      "4            Yes  \n",
      "\n",
      "[5 rows x 57 columns]\n",
      "✅ Drift simulated in batch_2_driftsim.csv — now test detection!\n",
      "MonthlyRevenue: PSI=0.104, KS p=0.000, Drift=True\n",
      "MonthlyMinutes: PSI=0.074, KS p=0.000, Drift=True\n",
      "TotalRecurringCharge: PSI=0.250, KS p=0.000, Drift=True\n",
      "DirectorAssistedCalls: PSI=1.098, KS p=0.089, Drift=True\n",
      "OverageMinutes: PSI=0.041, KS p=0.000, Drift=True\n",
      "RoamingCalls: PSI=0.026, KS p=0.849, Drift=False\n",
      "PercChangeMinutes: PSI=3.684, KS p=0.000, Drift=True\n",
      "PercChangeRevenues: PSI=1.320, KS p=0.000, Drift=True\n",
      "Drift Results: {'MonthlyRevenue': {'psi': np.float64(0.10395714155026198), 'ks_pvalue': np.float64(1.3764110664186989e-05), 'drift_detected': np.True_}, 'MonthlyMinutes': {'psi': np.float64(0.07400745662290881), 'ks_pvalue': np.float64(3.2043436465565116e-30), 'drift_detected': np.True_}, 'TotalRecurringCharge': {'psi': np.float64(0.2500149990772248), 'ks_pvalue': np.float64(4.467697858790576e-39), 'drift_detected': np.True_}, 'DirectorAssistedCalls': {'psi': np.float64(1.0977026059838917), 'ks_pvalue': np.float64(0.08875537813767365), 'drift_detected': np.True_}, 'OverageMinutes': {'psi': np.float64(0.041126211747322644), 'ks_pvalue': np.float64(0.0), 'drift_detected': np.True_}, 'RoamingCalls': {'psi': np.float64(0.026035264947036885), 'ks_pvalue': np.float64(0.8492024900952146), 'drift_detected': np.False_}, 'PercChangeMinutes': {'psi': np.float64(3.684145556484245), 'ks_pvalue': np.float64(1.2915387839743711e-10), 'drift_detected': np.True_}, 'PercChangeRevenues': {'psi': np.float64(1.3203161212423695), 'ks_pvalue': np.float64(6.28215477503712e-05), 'drift_detected': np.True_}}\n",
      "Overall Drift Detected: True\n"
     ]
    }
   ],
   "source": [
    "# Simulate Drift: Bump 'OverageMinutes' in batch 2 (e.g., +20% = more usage drift)\n",
    "batch2 = pd.read_csv(\"data/batches/batch_2.csv\")\n",
    "print(\"batch\",batch2.head(5))\n",
    "batch2['OverageMinutes'] += batch2['OverageMinutes'] * 0.2  # Fake shift \n",
    "batch2.to_csv(\"data/batches/batch_2_driftsim.csv\", index=False)\n",
    "print(\"✅ Drift simulated in batch_2_driftsim.csv — now test detection!\")\n",
    "\n",
    "# Quick Test: Detect drift between baseline (batch_0) and drifted batch_2\n",
    "from src.model.drift_detector import detect_drift\n",
    "baseline = pd.read_csv(\"data/batches/batch_0.csv\")\n",
    "drifted = pd.read_csv(\"data/batches/batch_2_driftsim.csv\")\n",
    "\n",
    "drifts, has_drift = detect_drift(baseline, drifted)\n",
    "print(\"Drift Results:\", drifts)\n",
    "print(f\"Overall Drift Detected: {has_drift}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4559ebbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4c9b433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Baseline F1: 0.458, AUC: 0.607\n",
      "✅ Retrained F1: 0.450 (delta: -0.009), AUC: 0.612 (delta: +0.005)\n",
      "✅ Versions: v1_baseline_20260108_2004 (F1 0.458) | v2_retrained_20260108_2004 (F1 0.450)\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from src.config import NUMERIC_FEATURES, CATEGORICAL_FEATURES, TARGET, MODEL_PARAMS\n",
    "\n",
    "# 1. Baseline on batch_0\n",
    "baseline_data = pd.read_csv(\"data/batches/batch_0.csv\")\n",
    "X_base = baseline_data[NUMERIC_FEATURES + CATEGORICAL_FEATURES]\n",
    "y_base = baseline_data[TARGET]\n",
    "\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X_base, y_base, test_size=0.2, random_state=42)\n",
    "model_base = XGBClassifier(**MODEL_PARAMS, random_state=42, eval_metric='logloss')\n",
    "model_base.fit(X_train_b, y_train_b)\n",
    "\n",
    "y_pred_b = model_base.predict(X_test_b)\n",
    "f1_base = f1_score(y_test_b, y_pred_b)\n",
    "auc_base = roc_auc_score(y_test_b, model_base.predict_proba(X_test_b)[:, 1])\n",
    "\n",
    "print(f\"✅ Baseline F1: {f1_base:.3f}, AUC: {auc_base:.3f}\")\n",
    "joblib.dump(model_base, 'models/baseline_model.pkl')  # mkdir models if needed\n",
    "\n",
    "# 2. Retrain on \"recent\" batches 1-4 (adapts to drift)\n",
    "recent_data = pd.concat([pd.read_csv(f\"data/batches/batch_{i}.csv\") for i in range(1, 5)], ignore_index=True)\n",
    "X_r = recent_data[NUMERIC_FEATURES + CATEGORICAL_FEATURES]\n",
    "y_r = recent_data[TARGET]\n",
    "\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_r, y_r, test_size=0.2, random_state=42)\n",
    "model_r = XGBClassifier(**MODEL_PARAMS, random_state=42, eval_metric='logloss')\n",
    "model_r.fit(X_train_r, y_train_r)\n",
    "\n",
    "y_pred_r = model_r.predict(X_test_r)\n",
    "f1_r = f1_score(y_test_r, y_pred_r)\n",
    "auc_r = roc_auc_score(y_test_r, model_r.predict_proba(X_test_r)[:, 1])\n",
    "\n",
    "print(f\"✅ Retrained F1: {f1_r:.3f} (delta: {f1_r - f1_base:+.3f}), AUC: {auc_r:.3f} (delta: {auc_r - auc_base:+.3f})\")\n",
    "joblib.dump(model_r, 'models/retrained_model.pkl')\n",
    "\n",
    "# 3. Versioning (simple MLOps touch)\n",
    "import datetime\n",
    "version_base = f\"v1_baseline_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
    "version_re = f\"v2_retrained_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
    "print(f\"✅ Versions: {version_base} (F1 {f1_base:.3f}) | {version_re} (F1 {f1_r:.3f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
